{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d62611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfcc885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator,LANGUAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993bbe19",
   "metadata": {},
   "source": [
    "# Google Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fadcfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    translator=Translator()\n",
    "    translated=translator.translate(text=text,dest=\"english\")\n",
    "    return translated.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55187657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4d9dd",
   "metadata": {},
   "source": [
    "# NLTK Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a480b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my', 'didn', \"aren't\", 'had', 'into', 'from', 'shouldn', 'by', 'doesn', 'over', 'under', \"hasn't\", 'here', 'than', 'her', \"wasn't\", 're', 'have', 'o', 'couldn', 'hasn', \"won't\", 'before', \"it's\", 'after', 'they', 'yours', 'for', 'themselves', 'ours', 'that', \"needn't\", 'been', 'in', 'shan', 'down', 'now', \"mustn't\", 'isn', 'no', \"shan't\", 'same', \"couldn't\", 'hadn', 'what', 'about', 'y', 'while', 'how', 'both', 'doing', 'because', \"you'll\", 'out', 'each', 'did', 'will', 'just', 'and', 'why', 'needn', 'ma', 'is', 'most', 'i', 'so', \"didn't\", 'its', \"wouldn't\", 'mightn', 'can', 'during', 'wasn', 'you', 'it', 'has', 'other', 'do', 'once', 'weren', 'itself', 'when', 'more', 'was', 'having', 'but', 'an', \"should've\", 'wouldn', 'with', 'until', 'our', 'which', 'whom', 'very', 'through', 'being', \"you're\", 'she', 'does', 'yourself', 've', \"don't\", 'to', \"shouldn't\", 'are', 'we', 'up', \"that'll\", 'off', 'm', 'these', 'the', 'were', 'further', 'aren', \"isn't\", 'am', 's', 'him', 'ain', 'at', 'against', 'theirs', 'their', 'be', 'all', 'this', 'where', \"weren't\", 'only', 'those', 'himself', 'hers', 'on', 'not', 'his', 'between', 'should', \"mightn't\", 'a', 'or', 'who', 'yourselves', 't', 'any', 'haven', \"you've\", 'there', \"doesn't\", 'nor', \"hadn't\", 'below', 'your', 'again', \"haven't\", 'too', 'don', \"she's\", 'of', 'won', 'if', 'ourselves', 'then', 'few', 'd', 'such', 'them', 'me', 'some', \"you'd\", 'mustn', 'herself', 'll', 'as', 'myself', 'he', 'above', 'own'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import pr\n",
    "stemmer=nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "#nltk.download('stopwords')\n",
    "stopword=set(stopwords.words(\"english\"))\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f74ba",
   "metadata": {},
   "source": [
    "# Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251e3a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"twitter_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb6264",
   "metadata": {},
   "source": [
    "# Labelling of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1acb9a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>No Foul and Offensive speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>No Foul and Offensive speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>Offensive language detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>No Foul and Offensive speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n",
       "24779  you've gone and broke the wrong heart baby, an...   \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...   \n",
       "24781              youu got wild bitches tellin you lies   \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n",
       "\n",
       "                             labels  \n",
       "0      No Foul and Offensive speech  \n",
       "1       Offensive language detected  \n",
       "2       Offensive language detected  \n",
       "3       Offensive language detected  \n",
       "4       Offensive language detected  \n",
       "...                             ...  \n",
       "24778   Offensive language detected  \n",
       "24779  No Foul and Offensive speech  \n",
       "24780   Offensive language detected  \n",
       "24781   Offensive language detected  \n",
       "24782  No Foul and Offensive speech  \n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels']=df['class'].map({0:\"Offensive language detected\",1:\"Offensive language detected\",2:\"No Foul and Offensive speech\"})\n",
    "df[['tweet','labels']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e75dc0",
   "metadata": {},
   "source": [
    "# Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb76c986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         rt mayasolovely woman shouldnt complain clean...\n",
       "1         rt  boy dats coldtyga dwn bad cuffin dat hoe ...\n",
       "2         rt urkindofbrand dawg rt  ever fuck bitch sta...\n",
       "3                 rt cganderson vivabased look like tranny\n",
       "4         rt shenikaroberts shit hear might true might ...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie   coreyemanuel right tl tras...\n",
       "24779    youve gone broke wrong heart baby drove rednec...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                    youu got wild bitches tellin lies\n",
       "24782    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(txt):\n",
    "    txt=str(txt).lower()\n",
    "    txt=re.sub('\\[.*?\\]','',txt)\n",
    "    txt=re.sub('https?://\\S+|www\\.\\S+','',txt)\n",
    "    txt=re.sub('<.*?>+','',txt)\n",
    "    txt=re.sub('[%s]' % re.escape(string.punctuation),'',txt)\n",
    "    txt=re.sub('\\n','',txt)\n",
    "    txt=re.sub('\\w*\\d\\w*','',txt)\n",
    "    txt=[word for word in txt.split(' ') if word not in stopword]\n",
    "    txt=\" \".join(txt)\n",
    "    return txt\n",
    "df['tweet']=df['tweet'].apply(clean)\n",
    "df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9951b30",
   "metadata": {},
   "source": [
    "# Prediction using Decison Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d907d272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.66670742144517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "x=np.array(df['tweet'])\n",
    "y=np.array(df['labels'])\n",
    "\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(x)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42)\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "accuarcy=accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(accuarcy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8030d",
   "metadata": {},
   "source": [
    "# Foul Detection in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92bc1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_text(test_data):\n",
    "    df=cv.transform([test_data]).toarray()\n",
    "    print(test_data)\n",
    "    return clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc60891d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stupid\n",
      "stupid\n",
      "['Offensive language detected']\n"
     ]
    }
   ],
   "source": [
    "enter_text=input()\n",
    "translated_text=translate(enter_text)\n",
    "prediction=check_text(translated_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c4890",
   "metadata": {},
   "source": [
    "# Foul Detection in Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59f7d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "\n",
    "\n",
    "def voiceanalysis():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Silence, please. Adjusting for ambient noise...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=2)  # Adjust based on ambient noise\n",
    "        print(\"Speak now please:\")\n",
    "\n",
    "        try:\n",
    "            audio = recognizer.listen(source)\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            text = text.lower()\n",
    "            print(text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return '0'\n",
    "        except sr.RequestError as e:\n",
    "            return '0'\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1527a4",
   "metadata": {},
   "source": [
    "# Video Analysis by comments and subtitles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1319e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# Replace YOUR_API_KEY with your actual API key and VIDEO_ID with the video ID\n",
    "def commentretriever(vid):\n",
    "    try:\n",
    "        API_KEY = input(\"Enter your youtube api key to proceed:\")\n",
    "        VIDEO_ID = vid\n",
    "\n",
    "\n",
    "        # Retrieving and Analysing Comments\n",
    "        URL = f\"https://www.googleapis.com/youtube/v3/commentThreads?key={API_KEY}&textFormat=plainText&part=snippet&videoId={VIDEO_ID}&maxResults=100\"\n",
    "        comments = []\n",
    "        def fetch_comments(url):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data['items']:\n",
    "\n",
    "                    comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                    comments.append(comment)\n",
    "\n",
    "                if 'nextPageToken' in data:\n",
    "                    next_page_url = URL + \"&pageToken=\" + data['nextPageToken']\n",
    "                    fetch_comments(next_page_url)\n",
    "\n",
    "        fetch_comments(URL)\n",
    "        return comments\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "     \n",
    "def subtitleretriever(vid):\n",
    "\n",
    "    # Retrieving and Analysing Subtitles\n",
    "    try:\n",
    "        subt=YouTubeTranscriptApi.get_transcript(vid)\n",
    "        subtitles=[]\n",
    "        for i in subt:\n",
    "            subtitles.append(i['text'])\n",
    "        return subtitles\n",
    "    except:\n",
    "        return []\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4662e09",
   "metadata": {},
   "source": [
    "# UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77f778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "root=Tk()\n",
    "root.geometry('1165x900')\n",
    "root['bg']='skyblue'\n",
    "root.title('MLFD')\n",
    "Label(root,text=\"MLFD\",font=\"Arial 20 bold\").pack()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# op=Text(root,width=50,height=1,wrap=WORD)\n",
    "# op.place(x=550,y=150)\n",
    "\n",
    "\n",
    "options=[\"Analyze Text\",\"Analyze Speech\",\"Video Context and Review Analysis\"]\n",
    "choose=ttk.Combobox(root,values=options,width=35)\n",
    "choose.place(x=125,y=150)\n",
    "\n",
    "\n",
    "    \n",
    "def method1():\n",
    "    Label(root,text=\"     Enter text       \",font=\"Arial 13 bold\").place(x=665,y=100)\n",
    "    inp=Entry(root,width=60)\n",
    "    inp.place(x=550,y=150)\n",
    "    def Testing1():\n",
    "        text=inp.get()\n",
    "        translated_text=translate(text)\n",
    "        prediction=check_text(translated_text)\n",
    "        Label(root,text=\"         Output            \",font=\"Arial 13 bold\").place(x=640,y=100)\n",
    "        op=Entry(root,width=60)\n",
    "        op.place(x=550,y=150)\n",
    "        op.insert(END,prediction[0])\n",
    "    btn=Button(root,text='Test',font=\"Arial 13 bold\",command=Testing1).place(x=700,y=200)\n",
    "    \n",
    "\n",
    "def method2():\n",
    "    def listening():\n",
    "        listbox = Listbox()\n",
    "        listbox.pack(padx=10, pady=10, expand=True)\n",
    "        listbox.place(x=125, y=350, width=500, height=250)\n",
    "        text=voiceanalysis()\n",
    "        if text=='0':\n",
    "            listbox.insert(END,\"Can't understand the language\")\n",
    "        else:\n",
    "            translated_text=translate(text)\n",
    "            allwords=list(translated_text.split())\n",
    "            allfoulwords=[]\n",
    "            for i in allwords:\n",
    "                prediction=check_text(i)\n",
    "                if prediction[0]=='Offensive language detected':\n",
    "                    allfoulwords.append(i)\n",
    "            foul_word_percent=(len(allfoulwords)/len(allwords))*100\n",
    "            fig1 = Figure(figsize=(2, 2), dpi=100)\n",
    "            plot1 = fig1.add_subplot(1, 1, 1)\n",
    "            labels1 = 'Hate', 'Clean'\n",
    "            colors1 = ['#ff9999', '#66b3ff']\n",
    "            sizes1 = [foul_word_percent,100-foul_word_percent]\n",
    "            plot1.pie(sizes1,colors=colors1, labels=labels1, autopct='%1.1f%%', startangle=90)\n",
    "            plot1.axis('equal')\n",
    "            canvas = FigureCanvasTkAgg(fig1)  \n",
    "            canvas.draw()\n",
    "            canvas.get_tk_widget().pack(side=TOP, fill=BOTH, expand=1)\n",
    "            canvas.get_tk_widget().place(x=755, y=350, width=250, height=250)\n",
    "            Label(root,text=\"speech analysis\",font=\"Arial 13 bold\").place(x=815,y=615)\n",
    "            listbox.insert(END,\"Speech is :\")\n",
    "            listbox.insert(END,\" \")\n",
    "            listbox.insert(END,text)\n",
    "            Label(root,text=\"         Output            \",font=\"Arial 13 bold\").place(x=640,y=100)\n",
    "            op=Entry(root,width=60)\n",
    "            op.place(x=550,y=150)\n",
    "            if len(allfoulwords):\n",
    "                op.insert(END,\"Foul and Offensive Speech\")\n",
    "            else:\n",
    "                op.insert(END,\"No Foul in Speech\")\n",
    "    listbox = Listbox()\n",
    "    listbox.pack(padx=10, pady=10, expand=True)\n",
    "    listbox.place(x=125, y=250, width=250, height=40)\n",
    "    listbox.insert(END,\"Silence, please. Adjusting for ambient noise...\")\n",
    "    listbox.insert(END,\"Click the button and speak please...\\n\\n\")\n",
    "    btn=Button(root,text='Speak',font=\"Arial 13 bold\",command=listening).place(x=400,y=255)\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "def findid(url):\n",
    "    l=len(url)\n",
    "    s=\"\"\n",
    "    for i in range(1,l-1):\n",
    "        if url[i]=='/' and url[i+1]!='/' and url[i-1]!='/':\n",
    "                for j in range(i+1,l):\n",
    "                    if(url[j]=='?'):\n",
    "                        return s\n",
    "                    s+=url[j]\n",
    "                \n",
    "def method3():\n",
    "    Label(root,text=\"Enter url of video\",font=\"Arial 13 bold\").place(x=665,y=100)\n",
    "    inp=Entry(root,width=60)\n",
    "    inp.place(x=550,y=150)\n",
    "    def Testing2():\n",
    "        text=inp.get()\n",
    "        vid=findid(text)\n",
    "        \n",
    "        allcomments=commentretriever(vid)\n",
    "        allsubtitles=subtitleretriever(vid)\n",
    "        allfoulcomments=[]\n",
    "        allfoulsubtitles=[]\n",
    "        \n",
    "        \n",
    "        if len(allcomments):\n",
    "            for i in allcomments:\n",
    "                translated_text=translate(i)\n",
    "                prediction=check_text(translated_text)\n",
    "                if(prediction[0]=='Offensive language detected'):\n",
    "                    allfoulcomments.append(i)\n",
    "            foul_comment_percent=(len(allfoulcomments)/len(allcomments))*100\n",
    "        else:\n",
    "            foul_comment_percent=0\n",
    "            \n",
    "        if len(allsubtitles):\n",
    "            for i in allsubtitles:\n",
    "                translated_text=translate(i)\n",
    "                prediction=check_text(translated_text)\n",
    "                if(prediction[0]=='Offensive language detected'):\n",
    "                    allfoulsubtitles.append(i)\n",
    "            foul_subtitle_percent=(len(allfoulsubtitles)/len(allsubtitles))*100\n",
    "        else:\n",
    "            foul_subtitle_percent=0\n",
    "        \n",
    "        \n",
    "        \n",
    "        Label(root,text=\"         Output            \",font=\"Arial 13 bold\").place(x=640,y=100)\n",
    "        op=Entry(root,width=60)\n",
    "        op.place(x=550,y=150)\n",
    "        if(foul_comment_percent+foul_subtitle_percent>40):\n",
    "            op.insert(END,'Video is not prefered to watch based on vulgarity analysis')\n",
    "        else:\n",
    "            op.insert(END,'Video is safe to watch')\n",
    "        \n",
    "        Label(root,text=\" allcomments \",font=\"Arial 13 bold\").place(x=70,y=275)\n",
    "        listbox1 = Listbox()\n",
    "        listbox1.pack(padx=10, pady=10, expand=True)\n",
    "        listbox1.place(x=10, y=300, width=250, height=250)\n",
    "        for item in allcomments:\n",
    "            listbox1.insert(END, item)\n",
    "        \n",
    "        Label(root,text=\"foulcomments\",font=\"Arial 13 bold\").place(x=70,y=575)\n",
    "        listbox2 = Listbox()\n",
    "        listbox2.pack(padx=10, pady=10, expand=True)\n",
    "        listbox2.place(x=10, y=600, width=250, height=250)\n",
    "        for item in allfoulcomments:\n",
    "            listbox2.insert(END, item)\n",
    "        \n",
    "        Label(root,text=\"allsubtitles\",font=\"Arial 13 bold\").place(x=675,y=275)\n",
    "        listbox3 = Listbox()\n",
    "        listbox3.pack(padx=10, pady=10, expand=True)\n",
    "        listbox3.place(x=605, y=300, width=250, height=250)\n",
    "        for item in allsubtitles:\n",
    "            listbox3.insert(END, item)\n",
    "        \n",
    "        Label(root,text=\"foulsubtitles\",font=\"Arial 13 bold\").place(x=675,y=575)\n",
    "        listbox4 = Listbox()\n",
    "        listbox4.pack(padx=10, pady=10, expand=True)\n",
    "        listbox4.place(x=605, y=600, width=250, height=250)\n",
    "        for item in allfoulsubtitles:\n",
    "            listbox4.insert(END, item)\n",
    "            \n",
    "        \n",
    "        fig1 = Figure(figsize=(2, 2), dpi=100)\n",
    "        plot1 = fig1.add_subplot(1, 1, 1)\n",
    "        labels1 = 'Hate', 'Clean'\n",
    "        colors1 = ['#ff9999', '#66b3ff']\n",
    "        sizes1 = [foul_comment_percent,100-foul_comment_percent]\n",
    "        plot1.pie(sizes1,colors=colors1, labels=labels1, autopct='%1.1f%%', startangle=90)\n",
    "        plot1.axis('equal')\n",
    "        canvas = FigureCanvasTkAgg(fig1)  \n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(side=TOP, fill=BOTH, expand=1)\n",
    "        canvas.get_tk_widget().place(x=305, y=300, width=250, height=250)\n",
    "        Label(root,text=\"comments analysis\",font=\"Arial 13 bold\").place(x=355,y=565)\n",
    "        \n",
    "        fig2 = Figure(figsize=(2, 2), dpi=100)\n",
    "        plot2 = fig2.add_subplot(1, 1, 1)\n",
    "        labels2 = 'Hate', 'Clean'\n",
    "        colors2 = ['#ff9999', '#66b3ff']\n",
    "        sizes2 = [foul_subtitle_percent,100-foul_subtitle_percent]\n",
    "        plot2.pie(sizes2,colors=colors2,labels=labels2, autopct='%1.1f%%', startangle=90)\n",
    "        plot2.axis('equal')\n",
    "        canvas = FigureCanvasTkAgg(fig2)  \n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(side=TOP, fill=BOTH, expand=1)\n",
    "        canvas.get_tk_widget().place(x=905, y=300, width=250, height=250)\n",
    "        Label(root,text=\"\",font=\"Arial 13 bold\").place(x=70,y=275)\n",
    "        Label(root,text=\"subtitles analysis\",font=\"Arial 13 bold\").place(x=965,y=565)\n",
    "        \n",
    "        \n",
    "    btn=Button(root,text='Test',font=\"Arial 13 bold\",command=Testing2).place(x=700,y=200)\n",
    "    \n",
    "def Proceed():\n",
    "    selected=choose.get()\n",
    "    if(selected==options[0]):\n",
    "        method1()\n",
    "    if(selected==options[1]):\n",
    "        method2()\n",
    "    if(selected==options[2]):\n",
    "        method3()\n",
    "        \n",
    "btn=Button(root,text='Proceed',font=\"Arial 13 bold\",command=Proceed).place(x=400,y=145)\n",
    "    \n",
    "    \n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a92058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
